pipelines:
  custom:
    cleanup-instance:
      - variables:
        - name: "AreYouSure"
          description: "Select yes if you want to cleanup the dangling images"
          default: "No"
          allowed-values:
            - "Yes"
            - "No"
      - step:
          name: "Checking your decision..."
          image: ubuntu:20.04
          script:
          - echo "You selected $AreYouSure"
          - echo "Processing..."
          - if [ "$AreYouSure" = "No" ]; then
          -   echo "Exiting... No cleanup performed."
          -   exit 0
          - fi
          - echo "Proceeding with cleanup of dangling images..."

          # Install openssh-client (needed for scp)
          - apt-get update -y && apt-get install -y openssh-client

          # Configure SSH access to EC2
          - echo "$EPASSADMIN_PROD_PEM" | base64 --decode > /tmp/bitbucket-ec2-key.pem
          - chmod 400 /tmp/bitbucket-ec2-key.pem

          - ssh -o StrictHostKeyChecking=no -i /tmp/bitbucket-ec2-key.pem ubuntu@107.23.170.41 'echo y | docker system prune -a && echo y | docker image prune'

    build-and-push:
      - variables:
          - name: "ImageTag"
            description: "Image tag value to build the image"
      - step:
          name: "Build Image and Push"
          image: amazon/aws-cli:latest
          services:
            - docker
          script:
            - echo "Running Build Pipeline..."
            # Authenticate Docker with AWS ECR
            - aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin "$ECR_IMAGE_URI:prod-$ImageTag"
            - docker build --build-arg ENV_FILE=.env.prod -t "$ECR_IMAGE_URI:prod-$ImageTag" .
            - docker push "$ECR_IMAGE_URI:prod-$ImageTag"

    deploy-to-ec2:
      - variables:
          - name: "ImageTag"
            description: "Image tag value to deploy the image"
      - step:
          name: "Deploying to EC2 Production"
          image: ubuntu:20.04
          script:
            - echo "Starting Deployment to EC2..."

            # Set AWS credentials from Bitbucket secrets
            - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
            - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
            - export AWS_DEFAULT_REGION=us-west-2

            # Install openssh-client (needed for scp)
            - apt-get update -y && apt-get install -y openssh-client gettext-base curl zip unzip
            # Use envsubst to replace ${ImageTag} in docker-compose.yaml
            - envsubst < docker-compose.yaml > docker-compose.updated.yaml

            # Configure SSH access to EC2
            - echo "$EPASSADMIN_PROD_PEM" | base64 --decode > /tmp/bitbucket-ec2-key.pem
            - chmod 400 /tmp/bitbucket-ec2-key.pem

            # Copy docker-compose.yml to EC2
            - scp -o StrictHostKeyChecking=no -i /tmp/bitbucket-ec2-key.pem docker-compose.updated.yaml nginx.conf ubuntu@107.23.170.41:/home/ubuntu/

            # SSH into EC2 and deploy with Docker Compose
            - ssh -o StrictHostKeyChecking=no -i /tmp/bitbucket-ec2-key.pem ubuntu@yourIP "aws ecr get-login-password --region us-east-1 | docker login --username AWS --aws_id.dkr.ecr.us-east-1.amazonaws.com && cd /home/ubuntu && docker compose -f docker-compose.updated.yaml down && docker compose -f docker-compose.updated.yaml up -d"

            # Run Django migrations
            - ssh -o StrictHostKeyChecking=no -i /tmp/bitbucket-ec2-key.pem ubuntu@IP'
                docker exec epass-application python manage.py makemigrations user &&
                docker exec epass-application python manage.py migrate &&
                docker exec epass-application python manage.py makemigrations &&
                docker exec epass-application python manage.py makemigrations myapp
                docker exec epass-application python manage.py migrate
